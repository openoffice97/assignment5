{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Linear Regression - Gradient Descent  \n",
    "\n",
    "<img src=\"./images/gradientDescent_animation.gif\" alt=\"Linear Regression w/Gradient Descent\" width=\"600\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assignment is divided to 2 parts\n",
    "* a simple dataset with 2 columns: 'attr','target'\n",
    "  * It will be used for training 1D linear regression model\n",
    "* An additional dataset, re: house prices\n",
    "  * It will be used for training a multivariant linear regression model\n",
    "* You will also need to implement other functions, such as a function for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 - 2D dataset\n",
    "* includes 2 columns: \n",
    "  * attr   - the attribute to use (a singe attribute x1 for every feature vector)\n",
    "  * target - the actual value (y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions:\n",
    "Please Read the following instructions, and make sure you follow all steps, before submiting your assignment via moodle:\n",
    "- Put your code one line after the '# YOUR CODE HERE' remark\n",
    "- You must remove the 'raise NotImplementedError()' exception raising line (which appears a line after the above remark).\n",
    "    * if you do not remove this line, it will be a sign that you didn't implement that code, and we won't be able to check your work\n",
    "- Do NOT remove any other line in this notebook    \n",
    "- you also need to implement the two functions 'myName', 'myId'\n",
    "    * myName - you need to return your full name as a string\n",
    "    * myId - you need to return your ID number as a an integer    \n",
    "- When you want to check your work, select the 'Cell' --> 'Run All' menu\n",
    "    * before performing your filnal test, we suggest to clear previous output (by selecting 'Cell' --> 'All output' --> 'Clear' menu) and then reperform the final execution ('Cell' --> 'Run All') of the code.\n",
    "    * after performing 'Run All', make sure there are no exceptions thrown and that the output is as you expected.\n",
    "- Don't forget to save your work, by clicking the 'save' icon (in the upper left part of the screen), or by selecting the 'File' --> 'Save and checkpoint' menu item. \n",
    "- Do NOT change the file name of this notebook\n",
    "- The work is done individualy, for each student\n",
    "- Each student needs to submit his/her assignment through moodle.\n",
    "- Submit the python notebook only (not any additional possible files) \n",
    "<br/><br/>\n",
    "Good Luck :-)<br/>\n",
    "The courses staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Student information methods:\n",
    "The following 2 cells consist of 2 methods which aim to validate your details.<br/>\n",
    "Please <b>make sure to implement <u>both</u> of them</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9b37d2297534714fc0f385d860f6b2f",
     "grade": false,
     "grade_id": "myName-Method",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return your full name (as a string)\n",
    "# example: assume your name is John Smith:\n",
    "# return 'John Smith'\n",
    "# ------------\n",
    "# return value:\n",
    "# - your full name (as a string)\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "def myName():\n",
    "    # ADD the return statement in the LINE AFTER: '# YOUR CODE HERE'\n",
    "    # REMOVE THE LINE: raise NotImplementedError()\n",
    "    # YOUR CODE HERE\n",
    "    raise 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf205f4550ee70f47db218c42b267bc7",
     "grade": false,
     "grade_id": "myIdMethod",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return your ID number (as an integer number)\n",
    "# example: assume your ID number is 1234:\n",
    "# return 1234 \n",
    "# ------------\n",
    "# return value:\n",
    "# - your ID number (as an integer number)\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "def myId():\n",
    "    # YOUR CODE HERE\n",
    "    raise 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc1c00a52491b254b78593fe73daf475",
     "grade": false,
     "grade_id": "student-details-testing",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests \n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "## 'myName' and 'myId' implementation methods\n",
    "# It tests the correctness their implementation\n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "aName = myName()\n",
    "aId = myId()\n",
    "assert aName is not None, 'no return student name'\n",
    "assert type(aName) is str, \"name is not a string: %r\" % aName\n",
    "print (\"'myName' method validation is successfull!\")\n",
    "print (\"your name is: %s\" %(aName))\n",
    "print (\"--------------------------------------\")\n",
    "assert aId is not None, 'no return student id'\n",
    "assert type(aId) is int, \"id is not an integer: %r\" % aId\n",
    "print (\"'myId' method validation is successfull!\")\n",
    "print (\"your id is: %d\" %(aId))\n",
    "## END OF 'myName' and 'myId' implementation validation\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Loading dataset - run only\n",
    "The following cells perform 5 things:\n",
    "* Preceding step - import packages\n",
    "* step 1 - load a dataset ----> run only\n",
    "* step 2 - split dataframe to X (feature vectors) and y (classes) ----> run only\n",
    "* step 3 - split the dataset to a train-set and a test-set ----> run only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import packages\n",
    "This step is necessary in order to use external packages. <br/><br/>\n",
    "<u>Some of the exteranl packages include</u>: \n",
    "* pandas - which we use mainly for dataframes and series\n",
    "* numpy - which we use for advance operations, such as unique values of arrays\n",
    "* random - which we could use to select random value (like we studied in earlier exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPORT (PACKAGES) CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# - Do NOT change or delete the following imports:\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "import math\n",
    "import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Note: do NOT add imports, such as sklearn, which could\n",
    "# answer the following questions.\n",
    "# --- add your imports here IF NEEDED:\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 1 - load the dataset ----> run only\n",
    "<img src=\"./images/load_dataframe.jpg\" alt=\"load dataframe\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84326a4d0211853f9bc14fc41e96005c",
     "grade": false,
     "grade_id": "loading_dataset_from_csv",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: trainTestSplit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method returns the dataset from the input csv file. \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - 'fileName' - full path of the csv fileName \n",
    "# ------------\n",
    "# return value:\n",
    "# - a dataframe structure containing the dataset\n",
    "# ---------------------\n",
    "def loadDataset(fileName):\n",
    "    return pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 2 - split dataframe to X (feature vectors) and y (classes) ----> run only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd242736645ef7465950f83eb39cafc2",
     "grade": false,
     "grade_id": "seperate_to_x_and_y",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: separateTo_X_and_y \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# ---- The method separates the input dataset into two parts:\n",
    "# 1. X (feature vectors)  \n",
    "# 2. y (categories) \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - dataset -  a dataframe structure, containing the dataset.\n",
    "# - classColName - the column name (string) containing the categories\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_featureVectors  - a dataframe containing all feature vectors. \n",
    "#                       It should contain the input dataframe after removing the class column.\n",
    "#                       The index of the X_featureVectores should be the same as the input dataframe parameter.\n",
    "# - y_Categories      - a series of containing all class values per instance.\n",
    "#                       The index of the y_Categories series should be the same as the input dataframe.\n",
    "# ---------------------\n",
    "def separateTo_X_and_y(dataset, classColName):\n",
    "    X_Vectors = dataset.drop(classColName,axis=1)\n",
    "    y_classes = dataset[classColName]\n",
    "    return X_Vectors,y_classes\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: join_X_and_y \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# ---- The method joins the input X_featureVectors dataframe and y_categories series into one dataset.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_featureVectors  - a dataframe containing all feature vectors. \n",
    "#                       The index of the X_featureVectores is expected to be the same as the y_Categories index.\n",
    "# - y_Categories      - a series of containing all class values per instance.\n",
    "# - classColName - the column name (string) containing the categories\n",
    "# ------------\n",
    "# return value:\n",
    "# - dataset -  a dataframe structure of the joined inputs,containing the dataset with the same indexes as the input parametes.\n",
    "# --------------------------------------------------------\n",
    "def join_X_and_y(X_featureVectores, y_Categories,classColName):\n",
    "    yCp = y_Categories.copy()\n",
    "    yCp.name=classColName\n",
    "    return pd.concat((X_featureVectores, yCp), axis=1)\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 3 - split the dataset to a train-set and a test-set ----> run only\n",
    "<img src=\"./images/train-test-split.png\" alt=\"train-test split\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "faa2feebfb7a80014b838e5332028f7c",
     "grade": false,
     "grade_id": "train-test-split",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: trainTestSplit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_vectors - a dataframe containing all feature vectors. \n",
    "# - y_categories - a series of containing all class values per instance.\n",
    "# - test_size_ratio - a number (0<number<1) of the wanted ratio of the dataset out of the dataset \n",
    "# - rand_state - a number, in order to guarantee reproducible results \n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - X_test -  a dataframe containing all feature vectors of the test set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# --------------------- \n",
    "def trainTestSplit(xInstances,yCategories,testRatio):\n",
    "    instanceIndx = [indx for indx in range(len(xInstances))]\n",
    "    random.shuffle(instanceIndx)\n",
    "    testSize = testRatio * len(instanceIndx)\n",
    "    trainIndxArr = list(instanceIndx)\n",
    "    testIndxArr = list()\n",
    "    while len(testIndxArr) < testSize:\n",
    "        indx = random.randrange(len(trainIndxArr))\n",
    "        testIndxArr.append(trainIndxArr.pop(indx))    \n",
    "    return xInstances.iloc[trainIndxArr], xInstances.iloc[testIndxArr], yCategories.iloc[trainIndxArr], yCategories.iloc[testIndxArr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f3add0b2f1b6537d01aad37797cfdd4",
     "grade": false,
     "grade_id": "display-info",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "df_1d_attr_target = loadDataset('.'+os.sep+'data'+os.sep+'2d_data.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_1d_attr_target, 'target')\n",
    "plt.scatter(X_vectors, y_categories)\n",
    "plt.show()\n",
    "df_1d_attr_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50e5ae7639918cb3370f6e730a1fdb8d",
     "grade": false,
     "grade_id": "2d-dataset-describe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "df_1d_attr_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "505cd7e7e72ac690ddacd466833e527d",
     "grade": false,
     "grade_id": "cell-8ef4596f256994f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(8)\n",
    "splitSize=0.2\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "xTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - 1D linear regression with gradient descent  \n",
    "<img src=\"./images/opt_momentum.png\" alt=\"bagging-classifier\" width=\"400\" align='center'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - univariate (1D) linear regression with gradient descent - 4 points\n",
    "The following cells perform a few things:\n",
    "* step 1 - univariate (linear regression) calculate yHat predictions ----> Student's implementation - total 1 point\n",
    "* step 2 - patial derivatives for w0, w1 ----> Student's implementation - total 1 point \n",
    "* step 3 - univariate linear regression fit-2d ----> Student's implementation - total 2 point \n",
    "  * The test for univariate linear regression fit is test also via the predict method (1 point for each test)\n",
    "* step 4 - gradient-descent-2d predict ----> run only (run the latter test as well - 1 out point of out 2 points for step 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43fac5aeaea43a89c716ede52a3c15ea",
     "grade": false,
     "grade_id": "univariate_LinearRegression_calc_yHat",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: univariate_LinearRegression_calc_yHat\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to calculate the value of the y_hat using the univariate linear regression model y_hat=w0+w1*x1.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_vectors - a dataframe containing all feature vectors for which we want to predict the y_hat values,\n",
    "#               using the univariat (one feature) linear regression model\n",
    "# - w0 - the w0 parameter of the linear regression model\n",
    "# - w1 - the w1 parameter of the linear regression model\n",
    "# ----\n",
    "# notes: \n",
    "#       * when using the intermediate linear regression model, during training, wo=wo_prev, w1=w1_prev, X_vectors=X_train\n",
    "#       * when using the trained linear regression model, during testing wo=wo_trained, w1=w1_trained, X_vectors=X_test \n",
    "# ------------\n",
    "# return value:\n",
    "# - y_hat - a series of the predictions for each input instance \n",
    "#  notes:\n",
    "#        * the y_hat prediction vector could be of an intermediate model during training or \n",
    "#          for prediction of new examples during evaluation\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def univariate_LinearRegression_calc_yHat(X_vectors, w0, w1):\n",
    "    # YOUR CODE HERE\n",
    "    h=w0+w1*X_vectors\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f5ef08546eeeb403a6a2c4519e9d73",
     "grade": false,
     "grade_id": "visualize_univariate_LinearRegression_calc_yHat",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - VISUALIZATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- visualization tests for the 'univariate_LinearRegression_calc_yHat' method \n",
    "\n",
    "\n",
    "def plotPointsAndLine(x1Series,y_Series,y_Hat):\n",
    "    # Plot the values\n",
    "    plt.scatter(x1Series, y_Series, c = 'b', marker='o')\n",
    "    plt.xlabel('attribute (x1)')\n",
    "    plt.ylabel('target (y)')\n",
    "\n",
    "    plt.plot([min(x1Series), max(x1Series)], [min(y_Hat), max(y_Hat)], color='red') \n",
    "\n",
    "    plt.show()    \n",
    "# --------------------------------------------------------\n",
    "\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "yHat = None\n",
    "# --------------------------------------------------------\n",
    "random.seed(12)\n",
    "splitSize=0.3\n",
    "df_1d_attr_target = loadDataset('.'+os.sep+'data'+os.sep+'2d_data.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_1d_attr_target, 'target')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "\n",
    "yHat = univariate_LinearRegression_calc_yHat(xTrain, 5, 1)\n",
    "\n",
    "x1TrainSeries = xTrain.iloc[:,-1]\n",
    "print('show some model and how it fits the data:')\n",
    "plotPointsAndLine(x1TrainSeries,yTrain,yHat)\n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a5166d195861e9b25a69ec04202f524",
     "grade": true,
     "grade_id": "test_univariate_LinearRegression_calc_yHat",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'univariate_LinearRegression_calc_yHat' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'univariate_LinearRegression_calc_yHat' output validation ...\")\n",
    "\n",
    "random.seed(13)\n",
    "splitSize=0.3\n",
    "df_1d_attr_target = loadDataset('.'+os.sep+'data'+os.sep+'2d_data.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_1d_attr_target, 'target')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "\n",
    "yHat = univariate_LinearRegression_calc_yHat(xTrain, 2, 1)\n",
    "assert [int(val) for val in yHat.iloc[0:3]]==[37,37,53], 'wrong values from linear regression output'\n",
    "\n",
    "print (\"----> The 'univariate_LinearRegression_calc_yHat' test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - step 1 - partial derivatives for w0,w1 ----> Student's implementation - total 1 point \n",
    "* In the <b>value_of_partialDerivatives_w0_w1</b> function you need to calculate the value of the <u>partial derivatives</u> of <u>wo</u> and <u>w1</u>.\n",
    "  * For each iteration we send the value of the prev w0 and w1 as input\n",
    "    * at the 1st round we sent the initial w0 and w1\n",
    "  * y_hat = wo_prev + w1_prev*x1\n",
    "    * x1 - the value of feature 1 (w1 is it's coefficient)\n",
    "    * the above is calculated for every example seperatly\n",
    "  * The <u>partial derivative of w0</u> = 2 * average(sum{for each example}(y_hat-y))\n",
    "  * The <u>partial derivative of w1</u> = 2 * average(sum{for each example}(y_hat-y)*x1)<br/>\n",
    "<img src=\"./images/wo_w1_partial_derivatives.png\" alt=\"wo_w1_partial_derivatives\" width=\"300\" align='left'/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Part 2 - step 1 - load the dataset ----> run only\n",
    "\n",
    "#Load the dataset\n",
    "dataset=pd.read_csv('2d_data.csv')\n",
    "\n",
    "#Part 2 - step 2 - split dataframe to X (feature vectors) and y (classes) ----> run only\n",
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,1].values\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n",
    "#Part 2 - step 3 - split the dataset to a train-set and a test-set ----> run only\n",
    "#ratio is 80:20 --> 80% data for training and 20% Data for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0702c24cf70ce325110bef8b9e498ad0",
     "grade": false,
     "grade_id": "partialDerivatives_w0_w1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: value_of_partialDerivatives_w0_w1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to calculate the value of the partial derivatives of w0 and w1.\n",
    "#     Note that the y_hat is calculated using 'univariate_LinearRegression_calc_yHat'\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - w0_prev - the w0 value from the previous iteration. If this is the first iteration w0_prev=w0 initial value\n",
    "# - w1_prev - the w1 value from the previous iteration. If this is the first iteration w1_prev=w1 initial value\n",
    "# - X_train - a dataframe containing all feature vectors of the train set.\n",
    "# - y_train - a series of containing all class values per train instance.\n",
    "# ------------\n",
    "# return values (comma seperated):\n",
    "# - value_of_w0_derivative - the value of the partial derivative w0\n",
    "# - value_of_w1_derivative - the value of the partial derivative w1\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "m = len(y)\n",
    "x_quad = [n/10 for n in range(0, 100)]\n",
    "y_quad = [(n-4)**2+5 for n in x_quad]\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "theta = np.array([0, 0])\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    \"\"\"\n",
    "    gradient_descent Performs gradient descent to learn theta\n",
    "    theta = GRADIENTDESENT(X, y, theta, alpha, num_iters) updates theta by \n",
    "    taking num_iters gradient steps with learning rate alpha\n",
    "    \"\"\"\n",
    "    cost_history = [0] * iterations\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        hypothesis = x.dot(theta)\n",
    "        loss = hypothesis-y\n",
    "        gradient = x.T.dot(loss)/m\n",
    "        theta = theta - alpha*gradient\n",
    "        cost = cost_function(x, y, theta)\n",
    "        cost_history[iteration] = cost\n",
    "\n",
    "    return theta, cost_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d94b49e42166c2e04272838103cabf7c",
     "grade": true,
     "grade_id": "test-partialDerivatives_w0_w1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'value_of_partialDerivatives_w0_w1' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'value_of_partialDerivatives_w0_w1' output validation ...\")\n",
    "\n",
    "random.seed(12)\n",
    "splitSize=0.3\n",
    "df_1d_attr_target = loadDataset('.'+os.sep+'data'+os.sep+'2d_data.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_1d_attr_target, 'target')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "\n",
    "\n",
    "w0_derivative, w1_derivative = value_of_partialDerivatives_w0_w1(1,1,xTrain,yTrain)\n",
    "assert (int(w0_derivative/10), int(w1_derivative/100))==(-4,-22), 'wrong values for partial derivatives'\n",
    "print ('\\npartial derivative for wo: %f' %(w0_derivative))\n",
    "print ('partial derivative for w1: %f\\n' %(w1_derivative))\n",
    "print (\"----> The 'value_of_partialDerivatives_w0_w1' test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - step 2 - gradient-descent-2d ----> Student's implementation - total 2 point \n",
    "<img src=\"./images/gradient-descent-univariate.png\" alt=\"gradient-descent-univariate.png\" width=\"600\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(x_train, y_train)\n",
    "#prediction of test set\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    " #visualizing the train set results\n",
    "plt.scatter(x_train, y_train, color='red')\n",
    "plt.plot(x_train, regressor.predict(x_train), color='blue')\n",
    "plt.title('(training set)')\n",
    "plt.xlabel('attr')\n",
    "plt.ylabel('target')\n",
    "plt.show()\n",
    " \n",
    "#visualizing the test set Results\n",
    "plt.scatter(x_test, y_test, color='red')\n",
    "plt.plot(x_train, regressor.predict(x_train), color='blue')\n",
    "plt.title('(test set)')\n",
    "plt.xlabel('attr')\n",
    "plt.ylabel('target')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "632f54f08958da9d7d6d9c5152242453",
     "grade": false,
     "grade_id": "univariateLinearRegression_fit",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: univariateLinearRegression_fit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- trains a univariate (one feature) linear regression model, using the gradient descent algorithm and returns w0 and w1.\n",
    "#     Note that the w0_derivative, w1_derivative are calculated,\n",
    "#      using 'value_of_partialDerivatives_w0_w1' in each iteration\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all feature vectors of the train set.\n",
    "# - y_train - a series of containing all class values per train instance.\n",
    "# - w0_initiail - the initial value of w0 \n",
    "# - w1_initiail - the initial value of w1\n",
    "# - alpha - the learning rate\n",
    "# - epochs - number of iterations to run gadient descent\n",
    "# ------------\n",
    "# return values (comma seperated):\n",
    "# - w0 - the trained value of wo\n",
    "# - w1 - the trained value of w1\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def univariateLinearRegression_fit(X_train,y_train,w0_initiail,w1_initiail,alpha,epochs):\n",
    "    ## use partialDerivative_w0_w1_ForTrainset\n",
    "    # YOUR CODE HERE\n",
    "    best_fit_x = np.linspace(0, 25, 20)\n",
    "    best_fit_y = [t[1] + t[0]*xx for xx in best_fit_x]\n",
    "    return best_fit_x,best_fit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21b97b77f2a2a99749ad880f884cace9",
     "grade": true,
     "grade_id": "univariateLinearRegression_fit-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'univariateLinearRegression_fit' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'univariateLinearRegression_fit' output validation ...\\n\")\n",
    "\n",
    "random.seed(13)\n",
    "splitSize=0.3\n",
    "df_1d_attr_target = loadDataset('.'+os.sep+'data'+os.sep+'2d_data.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_1d_attr_target, 'target')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "x1TrainSeries = xTrain.iloc[:,-1]\n",
    "\n",
    "trained_w0, trained_w1 = univariateLinearRegression_fit(xTrain,yTrain,0,0,0.00001,1)\n",
    "assert (int(trained_w0*1000),int(trained_w1*1000))==(1,73), 'wrong values for univariateLinearRegression_fit'\n",
    "print ('trained (1 epoch) wo,w1 = (%f,%f), plot on train points:' %(trained_w0, trained_w1))\n",
    "yHat=univariate_LinearRegression_calc_yHat(xTrain, trained_w0, trained_w1)\n",
    "plotPointsAndLine(x1TrainSeries,yTrain,yHat)\n",
    "\n",
    "trained_w0, trained_w1 = univariateLinearRegression_fit(xTrain,yTrain,0,0,0.00001,10)\n",
    "print ('trained (10 epoch) wo,w1 = (%f,%f), plot on train points:' %(trained_w0, trained_w1))\n",
    "yHat=univariate_LinearRegression_calc_yHat(xTrain, trained_w0, trained_w1)\n",
    "plotPointsAndLine(x1TrainSeries,yTrain,yHat)\n",
    "\n",
    "trained_w0, trained_w1 = univariateLinearRegression_fit(xTrain,yTrain,1,5,0.00001,100)\n",
    "assert (int(trained_w0*10),int(trained_w1*10))==(9,15), 'wrong values for univariateLinearRegression_fit'\n",
    "print ('trained (100 epochs) wo,w1 = (%f,%f), plot on train points:' %(trained_w0, trained_w1))\n",
    "yHat=univariate_LinearRegression_calc_yHat(xTrain, trained_w0, trained_w1)\n",
    "plotPointsAndLine(x1TrainSeries,yTrain,yHat)\n",
    "\n",
    "print (\"\\n----> The 'univariateLinearRegression_fit' test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "#-------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - step 4 - gradient-descent-2d predict ----> run only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b73b9586fca6838fae65c1e7408374ba",
     "grade": false,
     "grade_id": "univariateLinearRegression_predict",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: univariateLinearRegression_predict \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# ---- The method wraps the 'univariate_LinearRegression_calc_yHat' method and returns \n",
    "#      the linear regression predict on the test set.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_test - a dataframe containing all test feature vectors for which we want to predict the y_hat values,\n",
    "#               using the trained univariat (one feature) linear regression model\n",
    "# - trained_w0 - the trained w0 parameter of the linear regression model\n",
    "# - trained_w1 - the trained w1 parameter of the linear regression model\n",
    "# ------------\n",
    "# return value:\n",
    "# - y_hat - a series of the predictions for each input test instance \n",
    "# ---------------------\n",
    "def univariateLinearRegression_predict(X_test, trained_w0, trained_w1):\n",
    "    return univariate_LinearRegression_calc_yHat(X_test, trained_w0, trained_w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a66296c570e7fafb684c6866ca6ce934",
     "grade": true,
     "grade_id": "test_univariate_fit_via_predict",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'univariateLinearRegression_fit' method (via predict) \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'univariateLinearRegression_fit' (via predict) output validation ...\\n\")\n",
    "\n",
    "random.seed(13)\n",
    "splitSize=0.3\n",
    "df_1d_attr_target = loadDataset('.'+os.sep+'data'+os.sep+'2d_data.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_1d_attr_target, 'target')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "x1TestSeries = xTest.iloc[:,-1]\n",
    "\n",
    "trained_w0, trained_w1 = univariateLinearRegression_fit(xTrain,yTrain,0,0,0.00001,1)\n",
    "yHat=univariateLinearRegression_predict(xTest, trained_w0, trained_w1)\n",
    "assert (int(yHat.iloc[1]*10),int(yHat.iloc[4]*10))==(36,30), 'wrong values for predict (1 epoch)'\n",
    "print ('trained (1 epoch), plot on test points with train linear line:')\n",
    "plotPointsAndLine(x1TestSeries,yTest,yHat)\n",
    "\n",
    "trained_w0, trained_w1 = univariateLinearRegression_fit(xTrain,yTrain,0,0,0.00001,10)\n",
    "yHat=univariateLinearRegression_predict(xTest, trained_w0, trained_w1)\n",
    "print ('trained (10 epochs), plot on test points with train linear line:')\n",
    "plotPointsAndLine(x1TestSeries,yTest,yHat)\n",
    "\n",
    "trained_w0, trained_w1 = univariateLinearRegression_fit(xTrain,yTrain,1,5,0.00001,100)\n",
    "yHat=univariateLinearRegression_predict(xTest, trained_w0, trained_w1)\n",
    "assert (int(yHat.iloc[1]),int(yHat.iloc[3]))==(75,79), 'wrong values for predict (100 epoch)'\n",
    "print ('trained (100 epoch), plot on test points with train linear line:')\n",
    "plotPointsAndLine(x1TestSeries,yTest,yHat)\n",
    "\n",
    "print (\"\\n----> The 'univariateLinearRegression_fit' (via predict) test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "#-------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/multivariate-gradient_descent.png' alt=\"Drawing\" style=\"width: 200x\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Multivariat linear regression with gradient descent -  6 points\n",
    "The following cells perform a few things:\n",
    "* step 1 - load house pricing dataset ----> run only \n",
    "* step 2 - calc mean and std t-distribution values of a dataframe  ----> run only \n",
    "* step 3 - scale and de-scale data using t-score (remove mean, divide std) ----> Student's implementation - total 1 point \n",
    "* step 4 - gradient-descent-multivariate ----> Student's implementation - total 3 point \n",
    "* step 5 - linear regression - multivariate - predict ----> Student's implementation - total 1 point \n",
    "* step 6 - MSE - Mean Square Error  ----> Student's implementation - total 1 point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset - House pricing\n",
    "<img src='./images/For-sale-sign.jpg' alt=\"Drawing\" style=\"width: 200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar houses should be similar in price\n",
    "Expected to share similar attributes:<br/>\n",
    "* Square footage\n",
    "* Number of bedrooms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-7f8eaa7d6b58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mdf_2d_attr_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'house_pricing_data_2attrs.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mX_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseparateTo_X_and_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_2d_attr_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'displaying house pricing data: \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loadDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NOT CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "def plotPointsAndPricingLine(x_dataframe,y_Series,y_Hat):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = Axes3D(fig)\n",
    "    # Generate the values\n",
    "    x1_vals = x_dataframe.iloc[:, 0]\n",
    "    x2_vals = x_dataframe.iloc[:, 1]\n",
    "    y_vals = y_Series.iloc[:]/1000\n",
    "\n",
    "    ax.scatter(x1_vals, x2_vals, y_vals, c = 'b', marker='o')\n",
    "    ax.set_xlabel('size (feet^2)')\n",
    "    ax.set_ylabel('#rooms')\n",
    "    ax.set_zlabel('Price($K)')\n",
    "    \n",
    "    if y_Hat is not None:\n",
    "        ax.plot([min(x1_vals), max(x1_vals)], [min(x2_vals), max(x2_vals)],  [min(y_Hat/1000), max(y_Hat/1000)], color='red') \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "df_2d_attr_price = loadDataset('.'+os.sep+'data'+os.sep+'house_pricing_data_2attrs.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_2d_attr_price, 'price')\n",
    "print ('displaying house pricing data: \\n')\n",
    "plotPointsAndPricingLine(X_vectors, y_categories,None) # y_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 4 - step 3 - scale and de-scale data using t-score (remove mean, divide std) ----> Student's implementation - total 1 point\n",
    "<img src=\"./images/var_std_in_sample.png\" alt=\"var in sample\" style=\"width: 250px;\"/>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Part four - step 1 - load the dataset ----> run only\n",
    "\n",
    "#Load the dataset\n",
    "dataset=pd.read_csv('house_pricing_data_2attrs.csv')\n",
    "\n",
    "#Part four - step 2 - split dataframe to X (feature vectors) and y (classes) ----> run only\n",
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,2].values\n",
    "\n",
    "\n",
    "#Part four - step 3 - split the dataset to a train-set and a test-set ----> run only\n",
    "#ratio is 80:20 --> 80% data for training and 20% Data for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.2, random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train) \n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: t_distibution_mean_std\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# --- get the mean and std of the series\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - series - the input series to be scaled\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - mean_series - the mean value of the series \n",
    "# - std_series - the std value of the series (sample std as shown in the above figure, NOT population std)\n",
    "# --------------------------------------------------------\n",
    "def t_distibution_mean_std(series): \n",
    "    mean_series = series.mean()\n",
    "    n_minus_1=series.shape[0]-1\n",
    "    dist_from_mean = series-mean_series\n",
    "    std_series  = math.sqrt((dist_from_mean*dist_from_mean).sum()/n_minus_1)\n",
    "    return [mean_series,std_series]\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: t_distibution\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# --- get a dataframe consisting of the mean and std of each column in the dataset.\n",
    "# --- Notes: - the columns of the output dataframes correspond to the columns of the input dataframe\n",
    "#            - the 1st and 2nd rows (indexes) consist of the mean and std respectivly.\n",
    "#            - the std values consists of the sample std as shown in the above figure (and NOT the population std).\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - trainset - an input dataframe of the train set including both the X feature vectors and y categories to be scaled\n",
    "#              note: that the distribution is calculated on the trainset only and used both for train and test sets\n",
    "#                    for scaling.\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - mean_std_dataframe - a dataframe including the mean and std for each column \n",
    "# --------------------------------------------------------\n",
    "def t_distibution(trainset):\n",
    "    mean_std_dataframe = pd.DataFrame(columns=trainset.columns,index=['mean','std'])\n",
    "    for col in trainset.columns:\n",
    "        mean_std_dataframe[col]=t_distibution_mean_std(trainset[col])\n",
    "    return mean_std_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Show the mean & std for each column, including the categories:\n",
    "# --------------------------------------------------------\n",
    "\n",
    "random.seed(13)\n",
    "splitSize=0.3\n",
    "df_house_pricing = loadDataset('.'+os.sep+'data'+os.sep+'house_pricing_data_2attrs.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_house_pricing, 'price')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "train_set = join_X_and_y(xTrain, yTrain,'price')\n",
    "mean_std_dataframe = t_distibution(train_set)\n",
    "\n",
    "# \n",
    "print (\"Note: the following mean and std t-distribution values could vary, and depened on the train sampeling.\")\n",
    "print (\"\\t\\t please do not use the values themselves, but access values as shown as following:\\n---------\")\n",
    "print (\"the category's (price) std: %f \\t--->access using: mean_std_dataframe['price']['std']\" %(mean_std_dataframe['price']['std']))\n",
    "print (\"the 'bedroom's (number of bedrooms) mean: %f \\t--->access using: mean_std_dataframe['bedroom']['mean']\" %(mean_std_dataframe['bedroom']['mean']))\n",
    "print (\"---------\\nthe mean & std of size (feet^2): \\t--->access using: mean_std_dataframe['size']\\n%r\" %(mean_std_dataframe['size'])) \n",
    "print (\"---------\\nmean & std dataframe: \\n\")\n",
    "print(mean_std_dataframe)\n",
    "\n",
    "#--------------------------\n",
    "df_house_pricing = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "train_set=None\n",
    "mean_std_dataframe=None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 4 - step 2 - scale and de-scale data using t-score scale  ----> Student's implementation - total 1 point \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6cc89fa63f5d0cac9521f3f4a28da3",
     "grade": false,
     "grade_id": "t_scale_and_descale",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: t_scale_dataframe\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- scale a feature column, using the t-score scale. The t-distribution information is given as an input parameter.\n",
    "#     The scaling needs to be done for every column in the input dataframe. The function should return\n",
    "#     a dataframe with the same columns and indexes, but with the scaled values. \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - dataset - an input dataframe including both the X feature vectors and y categories to be scaled\n",
    "# - mean_std_dataframe - a dataframe including the mean and std for each column, to be used in scaling\n",
    "# ------------\n",
    "# return value:\n",
    "# - scaled dataset -  a dataframe containing the same columns and indexes, but with the scaled values.\n",
    "# ---------------------\n",
    "def t_scale_dataframe(dataset,mean_std_dataframe):\n",
    "    # YOUR CODE HERE\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_x=StandardScaler()\n",
    "    x_train=sc_x.fit_transform(x_train) \n",
    "    x_test=sc_x.fit_transform(x_test)\n",
    "    return x_train,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98b7586b9cdecc93627506e6690fff8a",
     "grade": true,
     "grade_id": "t_scale_attr-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 't_scale_dataframe' method\n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: t_descale_attr\n",
    "# ---------------------------\n",
    "# The following is performed:\n",
    "# --- de-scale (the opposite of scaling) the values of the input series, using the t-score scale.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - scaled_series -  a series containing scaled values.\n",
    "# - mean_std_series - a column from the mean_std_dataframe for descaling.\n",
    "# ------------\n",
    "# return value:\n",
    "# - de_scaled_series - a seires with the same indexes as the input series, containg the descaled values\n",
    "# --------------------------------------------------------\n",
    "def t_descale_series(scaled_series,mean_std_series):\n",
    "    return scaled_series*mean_std_series['std'] + mean_std_series['mean']\n",
    "    \n",
    "    \n",
    "print (\"check basic 't_scale_dataframe' output validation ...\\n\")\n",
    "random.seed(17)\n",
    "splitSize=0.3\n",
    "df_house_pricing = loadDataset('.'+os.sep+'data'+os.sep+'house_pricing_data_2attrs.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_house_pricing, 'price')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "train_set = join_X_and_y(xTrain, yTrain,'price')\n",
    "test_set  = join_X_and_y(xTest, yTest,'price')\n",
    "mean_std_dataframe = t_distibution(train_set)\n",
    "\n",
    "scaled_dataset = t_scale_dataframe(train_set,mean_std_dataframe)\n",
    "assert (int(scaled_dataset['price'].iloc[0]*10),int(scaled_dataset['price'].iloc[2]*10))==(2,-3), \"wrong scaled train set 'price' values\"\n",
    "\n",
    "de_scaled_price_series = t_descale_series(scaled_dataset['price'],mean_std_dataframe['price'])\n",
    "assert (int(de_scaled_price_series.iloc[0]/1000),int(de_scaled_price_series.iloc[2]/1000))==(369,299), \"wrong descaled train set 'price' values\"\n",
    "\n",
    "print ('train price (head) values          ---> %r' %(train_set['price'].head().tolist()))\n",
    "print ('train price scaled (head) values   ---> %s' %('['+','.join(['%7.3f...' %(price) for price in scaled_dataset['price'].head().tolist()]) +']'))\n",
    "print ('train price descaled (head) values ---> %r' %(de_scaled_price_series.head().tolist()))\n",
    "print (\"-------------------------\\n\")\n",
    "\n",
    "scaled_dataset = t_scale_dataframe(train_set,mean_std_dataframe)\n",
    "assert (int(scaled_dataset['size'].iloc[0]*10),int(scaled_dataset['size'].iloc[2]*100))==(4,-5), \"wrong scaled train set 'size' values\"\n",
    "\n",
    "de_scaled_size_series = t_descale_series(scaled_dataset['size'],mean_std_dataframe['size'])\n",
    "assert (int(de_scaled_size_series.iloc[0]/100),int(de_scaled_size_series.iloc[2]/100))==(24,19), \"wrong descaled train set 'size' values\"\n",
    "\n",
    "print ('train size (head) values          ---> %r' %(train_set['size'].head().tolist()))\n",
    "print ('train size scaled (head) values   ---> %s' %('['+','.join(['%7.3f...' %(price) for price in scaled_dataset['size'].head().tolist()]) +']'))\n",
    "print ('train size descaled (head) values ---> %r' %(de_scaled_size_series.head().tolist()))\n",
    "\n",
    "print (\"----------\\n----> The 't_scale_dataframe' tests passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "\n",
    "\n",
    "#--------------------------\n",
    "df_house_pricing = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - step 4 - linear regression - multivariate - predict ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34d29560c37715b0dedaed8cd649192b",
     "grade": false,
     "grade_id": "multivariateLinearRegression_predict",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: multivariateLinearRegression_predict\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# ---- The method should calulate and return\n",
    "#      the multivariate linear regression predict on the test set.\n",
    "#   Note: normaly the 'multivariateLinearRegression_predict' should show the predictions on the test\n",
    "#         feature vectors, but it could also be use as an intermediate step or to display a graph on training\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - x_featureVectors - a dataframe containing all feature vectors for which we want to predict the y_hat values,\n",
    "#                       using the trained multivariate linear regression model\n",
    "# - trained_w - the trained w vector linear regression paraneters.\n",
    "#               Note: the 'trained_w' vector includes the the weight of w0,\n",
    "#                     which is the weight in trained_w of the feature with the index 'attr0'.\n",
    "#                     The rest of the weights have the index keys like the column names\n",
    "#                     of the input x_featureVectors.\n",
    "# ------------\n",
    "# return value:\n",
    "# - y_hat - a series of the predictions for each input feature vector instances\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def multivariateLinearRegression_predict(x_featureVectors,trained_w):\n",
    "    # YOUR CODE HERE\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    regressor=LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    #prediction of test set\n",
    "    y_pred=regressor.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "247d36f624e81f47c6bfebd37ccf13f1",
     "grade": true,
     "grade_id": "test_multivariateLinearRegression_predict",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# The following method returns an initialized weight series:\n",
    "def initWeights(xTrain_columns,wieghtValueOrValues):\n",
    "    featureNames = [col for col in xTrain_columns]\n",
    "    featureNames.insert(0,'attr0')\n",
    "    valArrs = wieghtValueOrValues\n",
    "    if not isinstance(valArrs, list):\n",
    "        val = wieghtValueOrValues\n",
    "        if valArrs is None:\n",
    "            val = 0\n",
    "        valArrs = [val] * len(featureNames)    \n",
    "    return pd.Series(valArrs,index=featureNames)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'multivariateLinearRegression_predict' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'multivariateLinearRegression_predict' output validation ...\\n\")\n",
    "\n",
    "random.seed(13)\n",
    "splitSize=0.3\n",
    "df_house_pricing = loadDataset('.'+os.sep+'data'+os.sep+'house_pricing_data_2attrs.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_house_pricing, 'price')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "\n",
    "train_set = join_X_and_y(xTrain, yTrain,'price')\n",
    "test_set  = join_X_and_y(xTest, yTest,'price')\n",
    "mean_std_dataframe = t_distibution(train_set)\n",
    "scaled_trainset = t_scale_dataframe(train_set,mean_std_dataframe)\n",
    "scaled_xTrain,scaled_yTrain = separateTo_X_and_y(scaled_trainset, 'price')\n",
    "scaled_testset = t_scale_dataframe(test_set,mean_std_dataframe)\n",
    "scaled_xTest,scaled_yTest = separateTo_X_and_y(scaled_testset, 'price')\n",
    "wieghtValueOrValues = [300000, 30, 3000]\n",
    "w = initWeights(xTrain.columns,wieghtValueOrValues)\n",
    "yHat = multivariateLinearRegression_predict(xTest,w)\n",
    "assert (int(yHat.iloc[0]/1000),int(yHat.iloc[2]/1000))==(402,370), 'wrong values for multivariateLinearRegression_predict'\n",
    "\n",
    "\n",
    "print (\"displaying house pricing data\")\n",
    "print (\"Note - the output linear regression line (based on the given w vector) is not optimal and is only used for testing: \\n\")\n",
    "plotPointsAndPricingLine(xTest, yTest,yHat) # y_categories)\n",
    "\n",
    "print (\"\\n----> The 'multivariateLinearRegression_predict' tests passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "scaled_xTrain,scaled_yTrain = None,None\n",
    "scaled_testset,scaled_xTest,scaled_yTest = None,None,None\n",
    "scaled_trainset,scaled_xTrain,scaled_yTrain = None,None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - step 4 - gradient-descent-multivariate fit ----> Student's implementation - total 3 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "m = len(y)\n",
    "x_quad = [n/10 for n in range(0, 100)]\n",
    "y_quad = [(n-4)**2+5 for n in x_quad]\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "theta = np.array([0, 0])\n",
    "\n",
    "def cost_function(x, y, theta):\n",
    "    \"\"\"\n",
    "    cost_function(X, y, theta) computes the cost of using theta as the\n",
    "    parameter for linear regression to fit the data points in X and y\n",
    "    \"\"\"\n",
    "    ## number of training examples\n",
    "    m = len(y) \n",
    "    \n",
    "    ## Calculate the cost with the given parameters\n",
    "    J = np.sum((x.dot(theta)-y)**2)/2/m\n",
    "    \n",
    "    return J\n",
    "cost_function(x, y, theta)\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    \"\"\"\n",
    "    gradient_descent Performs gradient descent to learn theta\n",
    "    theta = GRADIENTDESENT(X, y, theta, alpha, num_iters) updates theta by \n",
    "    taking num_iters gradient steps with learning rate alpha\n",
    "    \"\"\"\n",
    "    cost_history = [0] * iterations\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        hypothesis = x.dot(theta)\n",
    "        loss = hypothesis-y\n",
    "        gradient = x.T.dot(loss)/m\n",
    "        theta = theta - alpha*gradient\n",
    "        cost = cost_function(x, y, theta)\n",
    "        cost_history[iteration] = cost\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9841a090c07cf0fb145e060161cbb012",
     "grade": false,
     "grade_id": "multivariateLinearRegression_fit",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: multivariateLinearRegression_fit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- trains a multivariate (two or more features) linear regression model, \n",
    "#     using the gradient descent algorithm and returns the wight vector w.\n",
    "#     Note that the w0_derivative, w1_derivative are calculated,\n",
    "#      using 'value_of_partialDerivatives_w0_w1' in each iteration\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all feature vectors of the train set.\n",
    "# - y_train - a series of containing all class values per train instance.\n",
    "# - initial_w - the initial value of the w vector (w - w0, w1,w2,...) \n",
    "#           Note: the 'initial_w' vector is a series data structure. It includes the the weight of w0,\n",
    "#                     which is the initial weight fo the w0 feature. It has with the index 'attr0'. \n",
    "#                     The rest of the initial weights have the index keys like the column names\n",
    "#                     of the input X_train.\n",
    "# - alpha - the learning rate\n",
    "# - epochs - number of iterations to run multivariate gadient descent\n",
    "# ------------\n",
    "# return value:\n",
    "# - trained_w - the values of the vector of weights (w) \n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def multivariateLinearRegression_fit(X_train,y_train,initial_w,alpha,epochs):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ## Plotting the best fit line\n",
    "    best_fit_x = np.linspace(0, 25, 20)\n",
    "    best_fit_y = [t[1] + t[0]*xx for xx in best_fit_x]\n",
    "    return best_fit-x,best_fit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3b6c7db39ae41a0e878c2a8ff2bc423",
     "grade": true,
     "grade_id": "test_multivariateLinearRegression_fit",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 3\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'multivariateLinearRegression_fit' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'multivariateLinearRegression_fit' output validation ...\\n\")\n",
    "\n",
    "random.seed(13)\n",
    "splitSize=0.2\n",
    "df_house_pricing = loadDataset('.'+os.sep+'data'+os.sep+'house_pricing_data_2attrs.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_house_pricing, 'price')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "\n",
    "train_set = join_X_and_y(xTrain, yTrain,'price')\n",
    "test_set  = join_X_and_y(xTest, yTest,'price')\n",
    "mean_std_dataframe = t_distibution(train_set)\n",
    "scaled_trainset = t_scale_dataframe(train_set,mean_std_dataframe)\n",
    "scaled_xTrain,scaled_yTrain = separateTo_X_and_y(scaled_trainset, 'price')\n",
    "scaled_testset = t_scale_dataframe(test_set,mean_std_dataframe)\n",
    "scaled_xTest,scaled_yTest = separateTo_X_and_y(scaled_testset, 'price')\n",
    "nWeights = xTrain.shape[1] + 1\n",
    "initial_w = initWeights(xTrain.columns,0)\n",
    "alpha = 0.01\n",
    "epochs=1\n",
    "trained_w = multivariateLinearRegression_fit(scaled_xTrain,scaled_yTrain,initial_w,alpha,epochs)\n",
    "assert int(trained_w[1]*1000)==16, 'wrong values for multivariateLinearRegression_fit'\n",
    "print ('trained (1 epochs) w=%r, plot on test points: \\n' %(str(trained_w.tolist())))\n",
    "yHat = multivariateLinearRegression_predict(scaled_xTest,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "#y_yhat = pd.DataFrame({'y':yTest,'yHat':de_scaled_yHat})\n",
    "plotPointsAndPricingLine(xTest, yTest,de_scaled_yHat)\n",
    "\n",
    "\n",
    "initial_w = initWeights(xTrain.columns,0)\n",
    "epochs=100\n",
    "alpha = 0.01\n",
    "trained_w = multivariateLinearRegression_fit(scaled_xTrain,scaled_yTrain,initial_w,alpha,epochs)\n",
    "assert int(trained_w[2]*100)==15, 'wrong values for multivariateLinearRegression_fit'\n",
    "print ('trained (100 epochs) w=%r, plot on test points:\\n' %(str(trained_w.tolist())))\n",
    "yHat = multivariateLinearRegression_predict(scaled_xTest,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "#y_yhat = pd.DataFrame({'y':yTest,'yHat':de_scaled_yHat})\n",
    "#print (y_yhat.head())\n",
    "plotPointsAndPricingLine(xTest, yTest,de_scaled_yHat)\n",
    "print (\"\\n----> The 'multivariateLinearRegression_fit' test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "scaled_xTrain,scaled_yTrain = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - step 5 - MSE - Mean Square Error  ----> Student's implementation - total 1 point \n",
    "<img src=\"./images/mse-explained.png\" alt=\"bagging-classifier\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4904c544aa07a227c66ef39dfa6525f7",
     "grade": false,
     "grade_id": "calc_mse",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_mse\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- check the MSE (mean squared error) as shown in the above image,\n",
    "#     for running the predicted linear regression values compared to the actual test values\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y          - the actual expected values\n",
    "# - yPredicted - the predicted expected values\n",
    "# ------------\n",
    "# return value:\n",
    "# - mse (mean squared error) value\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def calc_mse(y,yPredicted):\n",
    "    ## use partialDerivative_w0_w1_ForTrainset\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6134ee6739931176a4e99d31adf1f9e6",
     "grade": true,
     "grade_id": "calc_mse-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'calc_mse' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'calc_mse' output validation ...\")\n",
    "\n",
    "random.seed(15)\n",
    "splitSize=0.2\n",
    "df_house_pricing = loadDataset('.'+os.sep+'data'+os.sep+'house_pricing_data_2attrs.csv')\n",
    "X_vectors, y_categories = separateTo_X_and_y(df_house_pricing, 'price')\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(X_vectors, y_categories,splitSize)\n",
    "\n",
    "train_set = join_X_and_y(xTrain, yTrain,'price')\n",
    "test_set  = join_X_and_y(xTest, yTest,'price')\n",
    "mean_std_dataframe = t_distibution(train_set)\n",
    "scaled_trainset = t_scale_dataframe(train_set,mean_std_dataframe)\n",
    "scaled_xTrain,scaled_yTrain = separateTo_X_and_y(scaled_trainset, 'price')\n",
    "scaled_testset = t_scale_dataframe(test_set,mean_std_dataframe)\n",
    "scaled_xTest,scaled_yTest = separateTo_X_and_y(scaled_testset, 'price')\n",
    "\n",
    "nWeights = xTrain.shape[1] + 1\n",
    "initial_w = initWeights(xTrain.columns,0)\n",
    "alpha = 0.03\n",
    "epochs=10\n",
    "trained_w = multivariateLinearRegression_fit(scaled_xTrain,scaled_yTrain,initial_w,alpha,epochs)\n",
    "yHat = multivariateLinearRegression_predict(scaled_xTest,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "# calculate mse in k$:\n",
    "mse_descaled = calc_mse(yTest/1000,de_scaled_yHat/1000)\n",
    "mse_scaled   = calc_mse(scaled_yTest,yHat)\n",
    "assert int(mse_descaled)==6219, 'wrong values for calc_mse'\n",
    "print('trained (10 epochs) mse_descaled (mse in square k$): %5.1f' %(mse_descaled))\n",
    "print('trained (10 epochs) mse_scaled: %5.3f' %(mse_scaled))\n",
    "print ('trained (10 epochs) w=%r, plot on test points: \\n' %(str(trained_w.tolist())))\n",
    "plotPointsAndPricingLine(xTest, yTest,de_scaled_yHat)\n",
    "\n",
    "\n",
    "initial_w = initWeights(xTrain.columns,0)\n",
    "epochs=100\n",
    "alpha = 0.03\n",
    "trained_w = multivariateLinearRegression_fit(scaled_xTrain,scaled_yTrain,initial_w,alpha,epochs)\n",
    "yHat = multivariateLinearRegression_predict(scaled_xTest,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "# calculate mse in k$:\n",
    "mse_descaled = calc_mse(yTest/1000,de_scaled_yHat/1000)\n",
    "mse_scaled   = calc_mse(scaled_yTest,yHat)\n",
    "assert int(mse_descaled)==2853, 'wrong values for calc_mse'\n",
    "print ('trained (100 epochs) w=%r, plot on test points:\\n' %(str(trained_w.tolist())))\n",
    "print('trained (100 epochs)mse_descaled (mse in square k$): %5.1f' %(mse_descaled))\n",
    "print('trained (100 epochs)mse_scaled: %5.3f' %(mse_scaled))\n",
    "\n",
    "plotPointsAndPricingLine(xTest, yTest,de_scaled_yHat)\n",
    "\n",
    "# -------\n",
    "print (\"----> The 'calc_mse' test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
